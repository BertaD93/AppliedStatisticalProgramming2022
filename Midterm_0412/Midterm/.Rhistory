# fit a lm using training set
model <- lm(overreporting ~ black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting+catholic+prot+bornagain+chatthtl, data=training)
test.fitted <- predict(model, test)# find fitted values with test data
test.fitted[test.fitted < 0] <- 0
test.fitted[test.fitted > 1 ] <- 1
# calculate residuals and add it to the vector
resid_Kfold <- c(resid_Kfold, test$overreporting - test.fitted)
}
# calculate MSE
mean(resid_Kfold^2)
#a
load("C:/Users/Tita/Downloads/cces2010sub.RData")
library(tidyverse)
df <- cces2010sub %>% mutate(polknow= polknow1+polknow2+polknow3+polknow4+polknow5) %>%
mutate(overreporting = case_when((voted10unv == 1 & voted == 0) ~ 1,(voted10unv == 0 & voted == 0) ~ 0)) %>%
mutate(income = na_if(income, "Skipped")) %>%
mutate(income = na_if(income, "Not Asked")) %>%
mutate(income = na_if(income, "Prefer not to say"))
df <- df %>% drop_na()
df$birthyrsq <- df$birthyr^2
#We want to measure the over-reporting, which mean a people who not voted but say they voted (voted10unv = 1 and voted = 0). In contrast to this voters, the citizens who do not vote and report not voting (voted10unv = 0 and voted= 0) will be the effect of not over reporting. In this sense, to proof the hypothesis we need to code over-reporting as we already code it. The other two options (voted10unv = 0 and voted = 1 or individuals with voted10unv =1 and voted = 1) is the opposite of our desire outcome variable. Those two variable measure the under-reporting because is people who vote but they report that did not vote. The people who vote and tell the true is the effect of not under reporting, so it helps to measure the under reporting. However, we want over-reporting and that is why we choose the first option.
#We lost 46174 observations. The data frame without missing values have 9225 observations.
#b
#####First model####
first_model <- summary(lm(overreporting ~ black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting, data=df ))
# set seed
set.seed(1234)
# let's set K = 10
folds <- sample(1:10, nrow(df), replace = T)
resid_Kfold <- NULL
resid_Kfold <- c()
for (i in 1:10){ # i is the indicator for each iteration
training <- df[folds != i, ]# separate training and test set
test <- df[folds == i, ]
# fit a lm using training set
model <- lm(overreporting ~  black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting, data=training)
# find fitted values with test data
test_fitted <- predict(model, test)
test_fitted[test_fitted < 0] <- 0
test_fitted[test_fitted > 1 ] <- 1
# calculate residuals and add it to the vector
resid_Kfold <- c(resid_Kfold, test$overreporting - test_fitted)
}
# calculate MSE
mean(resid_Kfold^2)
#####Second model####
second_model <- summary(lm(overreporting ~ black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting+catholic+prot+bornagain+chatthtl, data=df ))
set.seed(1234)
# let's set K = 10
folds <- sample(1:10, nrow(df), replace = T)
resid_Kfold <- NULL
resid_Kfold <- c()
for (i in 1:10){ # i is the indicator for each iteration
training <- df[folds != i, ] # separate training and test set
test <- df[folds == i, ]
# fit a lm using training set
model <- lm(overreporting ~ black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting+catholic+prot+bornagain+chatthtl, data=training)
test_fitted <- predict(model, test)# find fitted values with test data
test_fitted[test_fitted < 0] <- 0
test_fitted[test_fitted > 1 ] <- 1
# calculate residuals and add it to the vector
resid_Kfold <- c(resid_Kfold, test$overreporting - test_fitted)
}
# calculate MSE
mean(resid_Kfold^2)
0.1611046-0.1601671
library(devtools)
library(roxygen2)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
current.code <- as.package("Midterm")
load_all(current.code)
document(current.code)
current.code <- as.package("Midterm")
load_all(current.code)
document(current.code)
solve((t(X) %*% X+ l * diag(nrow = ncol(X), ncol = ncol(X)))) %*% t(X) %*%  y
#b
#####First model####
first_model <- summary(lm(overreporting ~ black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting, data=df ))
#a
load("C:/Users/Tita/Downloads/cces2010sub.RData")
library(tidyverse)
df <- cces2010sub %>% mutate(polknow= polknow1+polknow2+polknow3+polknow4+polknow5) %>%
mutate(overreporting = case_when((voted10unv == 1 & voted == 0) ~ 1,(voted10unv == 0 & voted == 0) ~ 0)) %>%
mutate(income = na_if(income, "Skipped")) %>%
mutate(income = na_if(income, "Not Asked")) %>%
mutate(income = na_if(income, "Prefer not to say"))
df <- df %>% drop_na()
df$birthyrsq <- df$birthyr^2
#We want to measure the over-reporting, which mean a people who not voted but say they voted (voted10unv = 1 and voted = 0). In contrast to this voters, the citizens who do not vote and report not voting (voted10unv = 0 and voted= 0) will be the effect of not over reporting. In this sense, to proof the hypothesis we need to code over-reporting as we already code it. The other two options (voted10unv = 0 and voted = 1 or individuals with voted10unv =1 and voted = 1) is the opposite of our desire outcome variable. Those two variable measure the under-reporting because is people who vote but they report that did not vote. The people who vote and tell the true is the effect of not under reporting, so it helps to measure the under reporting. However, we want over-reporting and that is why we choose the first option.
#We lost 46174 observations. The data frame without missing values have 9225 observations.
#b
#####First model####
first_model <- summary(lm(overreporting ~ black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting, data=df ))
# set seed
set.seed(1234)
# let's set K = 10
folds <- sample(1:10, nrow(df), replace = T)
resid_Kfold <- NULL
resid_Kfold <- c()
for (i in 1:10){ # i is the indicator for each iteration
training <- df[folds != i, ]# separate training and test set
test <- df[folds == i, ]
# fit a lm using training set
model <- lm(overreporting ~  black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting, data=training)
# find fitted values with test data
test_fitted <- predict(model, test)
test_fitted[test_fitted < 0] <- 0
test_fitted[test_fitted > 1 ] <- 1
# calculate residuals and add it to the vector
resid_Kfold <- c(resid_Kfold, test$overreporting - test_fitted)
}
# calculate MSE
mean(resid_Kfold^2)
#####Second model####
second_model <- summary(lm(overreporting ~ black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting+catholic+prot+bornagain+chatthtl, data=df ))
set.seed(1234)
# let's set K = 10
folds <- sample(1:10, nrow(df), replace = T)
resid_Kfold <- NULL
resid_Kfold <- c()
for (i in 1:10){ # i is the indicator for each iteration
training <- df[folds != i, ] # separate training and test set
test <- df[folds == i, ]
# fit a lm using training set
model <- lm(overreporting ~ black+ hisp + asian + other + mixed +male+educ+ income+ birthyr+birthyrsq+polknow+rep+ind+ideo7ltc+attmeeting+catholic+prot+bornagain+chatthtl, data=training)
test_fitted <- predict(model, test)# find fitted values with test data
test_fitted[test_fitted < 0] <- 0
test_fitted[test_fitted > 1 ] <- 1
# calculate residuals and add it to the vector
resid_Kfold <- c(resid_Kfold, test$overreporting - test_fitted)
}
# calculate MSE
mean(resid_Kfold^2)
#The difference between the first and the second model is not really significant, because the improvement is 0.0009375. In this sense, adding the religous covariates do not make the model extremly more robust.
library(glmnet)
df_ridgef <- df %>% relocate(overreporting) %>% select(overreporting,black, hisp ,asian , other,mixed,male,educ, income,birthyr,birthyrsq,polknow,rep,ind,ideo7ltc,attmeeting)
lambda_list <- seq(0,.01, length=10)
mse_test <- c()
x <- data.matrix(df_ridgef[ ,2:16])
y <- as.numeric(df_ridgef[ ,1])
cv_model <- cv.glmnet(x, y, alpha = 0)
best_lambda <- cv_model$lambda.min
best_lambda
#set.seed(1234)
# let's set K = 10
folds <- sample(1:10, nrow(df_ridgef), replace = T)
for (j in 1:10) {
mse_test_fold <- c()
for (i in 1:10){
training <- df_ridgef[folds != i, ]
test <- df_ridgef[folds == i, ]
xtest <- data.matrix(test[,2:16])
X <- data.matrix(training[ ,2:16])
y <- as.numeric(training[ ,1])
model <- solve((t(X) %*% X+ lambda_list[j] * diag(nrow = ncol(X), ncol = ncol(X)))) %*% t(X) %*%  y
test.fitted <- predict(model, xtest)
test.fitted[test.fitted < 0] <- 0
test.fitted[test.fitted > 1 ] <- 1
mse_test_fold[i] <- mean((test$overreporting - test.fitted)^2)
}
mse_test[j] <- mean(mse_test_fold)
}
#' Maximum likelihood
#'
#' Calculates the maximum likelihood estimator for lambda
#'
#' @param y numeric. The vector of observed data
#'
#' @author Berta Diaz
#'
#' @return
#' @export
#'
#' @examples
#' y=c(1,2,3,4)
#' mle(y)
setGeneric( #Create a generic
name = "mle",
def = function(y)
{standardGeneric("mle")}
)
#' @export
setMethod( #Create the function to calculate the Maximum likelihood
f = "mle",
definition = function(y){#Number of observations
n <- length(y) #Number of observations
mle <- sum(y)/n #Sum of y over n
return(mle) #Return the mle
}
)
folds <- sample(1:10, nrow(df_ridgef), replace = T)
for (j in 1:10) {
mse_test_fold <- c()
for (i in 1:10){
training <- df_ridgef[folds != i, ]
test <- df_ridgef[folds == i, ]
xtest <- data.matrix(test[,2:16])
X <- data.matrix(training[ ,2:16])
y <- as.numeric(training[ ,1])
model <- solve((t(X) %*% X+ lambda_list[j] * diag(nrow = ncol(X), ncol = ncol(X)))) %*% t(X) %*%  y
test_fitted <- model %*% test
test_fitted[test_fitted < 0] <- 0
test.fitted[test_fitted > 1 ] <- 1
mse_test_fold[i] <- mean((test$overreporting - test.fitted)^2)
}
mse_test[j] <- mean(mse_test_fold)
}
#' @export
setMethod( #Set Method
f = "standardError",
definition = function(y, SEtype, ...){ #Start the function
n <-length(y) #Number of observations in y
if(SEtype == "basic"){ #Create a function
se_basic <- sqrt(mle(y)/n) #Calculate basic standard error
return(se_basic)
} else if(SEtype == "bootstrap"){
B <- 50 #The B is going to be equal to 50
samples = list()
for(i in 1:B) {
samples[[i]] <-  sample(y, n, replace= TRUE) #Set a sample with size n, replacement
}
msample <- matrix(unlist(samples), n, B) #Matrix form
mean_mle <- apply(msample, 2, mle) #Calculate the mle throughout all the matrix with apply
sdev <- sd(mean_mle) #Calculate the standard deviation
return(sdev) #Return the standard deviation
} else {
stop("SEtype not sopported!") #In case the rule is not supported, then stopped
}
}
)
training <- df_ridgef[folds != i, ]
test <- df_ridgef[folds == i, ]
xtest <- data.matrix(test[,2:16])
X <- data.matrix(training[ ,2:16])
y <- as.numeric(training[ ,1])
model <- solve((t(X) %*% X+ lambda_list[j] * diag(nrow = ncol(X), ncol = ncol(X)))) %*% t(X) %*%  y
View(model)
View(test)
View(xtest)
test <- df_ridgef[folds == i, ]
test_fitted <- model %*% test
View(model)
ytest<- data.matrix(test[1,])
test_fitted <- model %*% ytest
for (j in 1:10) {
mse_test_fold <- c()
for (i in 1:10){
training <- df_ridgef[folds != i, ]
test <- df_ridgef[folds == i, ]
ytest<- data.matrix(test[1,])
xtest <- data.matrix(test[,2:16])
X <- data.matrix(training[ ,2:16])
y <- as.numeric(training[ ,1])
model <- solve((t(X) %*% X+ lambda_list[j] * diag(nrow = ncol(X), ncol = ncol(X)))) %*% t(X) %*%  y
test_fitted <- model %*% ytest
test_fitted[test_fitted < 0] <- 0
test_fitted[test_fitted > 1 ] <- 1
mse_test_fold[i] <- mean((test$overreporting - test_fitted)^2)
}
mse_test[j] <- mean(mse_test_fold)
}
for (j in 1:10) {
mse_test_fold <- c()
for (i in 1:10){
training <- df_ridgef[folds != i, ]
test <- df_ridgef[folds == i, ]
ytest<- data.matrix(test[1,])
xtest <- data.matrix(test[,2:16])
X <- data.matrix(training[ ,2:16])
y <- as.numeric(training[ ,1])
model <- solve((t(X) %*% X+ lambda_list[j] * diag(nrow = ncol(X), ncol = ncol(X)))) %*% t(X) %*%  y
test_fitted <- model %*% ytest
test_fitted[test_fitted < 0] <- 0
test_fitted[test_fitted > 1 ] <- 1
mse_test_fold[i] <- mean((ytest - test_fitted)^2)
}
mse_test[j] <- mean(mse_test_fold)
}
training <- df_ridgef[folds != i, ]
test <- df_ridgef[folds == i, ]
ytest<- data.matrix(test[1,])
xtest <- data.matrix(test[,2:16])
X <- data.matrix(training[ ,2:16])
y <- as.numeric(training[ ,1])
model <- solve((t(X) %*% X+ lambda_list[j] * diag(nrow = ncol(X), ncol = ncol(X)))) %*% t(X) %*%  y
test_fitted <- model %*% ytest
test_fitted[test_fitted < 0] <- 0
test_fitted[test_fitted > 1 ] <- 1
mse_test_fold[i] <- mean((ytest - test_fitted)^2)
View(ytest)
View(test_fitted)
test_fitted <- model %*% ytest
test_fitted[test_fitted < 0] <- 0
test_fitted[test_fitted > 1 ] <- 1
mse_test_fold[i] <- mean((ytest - test_fitted)^2)
mean((ytest - test_fitted)^2)
View(ytest)
test_fitted <- model %*% test
test_fitted <- model %*% ytest
test_fitted[test_fitted < 0] <- 0
test_fitted[test_fitted > 1 ] <- 1
mse_test_fold[i] <- mean((ytest - test_fitted)^2)
ytest - test_fitted
#Scale data
df_ridgef <- data.matrix(df_ridgef[ ,1:16])
df_norm <- apply(df_ridgef, 2, scale) #normalize
x <- data.matrix(df_norm[ ,2:16])
y <- as.numeric(df_norm[ ,1])
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE)
library(data.table)
library(glmnet)
load("cces2010sub.RData")
cces2010sub <- as.data.table(cces2010sub)
# Create a new variable such that by row index, it sums across all polknow variables, ignoring NA.
cces2010sub[,`:=`("polknow" = sum(polknow1, polknow2, polknow3, polknow4, polknow5, na.rm = TRUE)), by=1:NROW(cces2010sub)]
# Check that results are reasonable
head(cces2010sub[,.(polknow1, polknow2, polknow3, polknow4, polknow5,polknow)])
cces2010sub[,`:=`("overreporting" = ifelse(voted10unv==1 & voted==0, 1, ifelse(voted10unv==0 & voted==0, 0, NA)))]
summary(cces2010sub$overreporting)
sum(cces2010sub$overreporting, na.rm = TRUE)
cces2010sub[income %in% c("Skipped", "Not Asked" , "Prefer not to say"), income := NA]
summary(cces2010sub$income)
str(cces2010sub$income)
# Re-factor to reset levels
cces2010sub[, income := factor(income)]
# Store original number of observations
original_obvs <- nrow(cces2010sub)
# Omit any observations with missing values in any variable
cces2010sub <- na.omit(cces2010sub)
# Store new number of observations
new_obvs <- nrow(cces2010sub)
# See how many observations lost
original_obvs - new_obvs
paste0(round((original_obvs - new_obvs) / original_obvs * 100 ,2), "%")
# Define birthyr squared
cces2010sub[,"birthyrsq" := (birthyr)^2]
# Create model object
or_ols <- lm(overreporting ~ black + hisp + asian + other + mixed + male + educ + income + birthyr +  birthyrsq + polknow + rep + ind + ideo7ltc + attmeeting, cces2010sub)
# View summary
summary(or_ols)
# Define data splits
set.seed(1234)
folds <- sample(10, nrow(cces2010sub), replace = TRUE)
# Define a function that takes a row index and a model object
pred_fold <- function(i, mod_desc){
# We will test on the iterated holdout fold...
test <- cces2010sub[folds == 1]
# and train on the rest of the rows
training <- cces2010sub[folds != 1]
temp_mod <- lm(mod_desc, training)
# Use our  model and the holdout fold to predict
fitted <- predict(temp_mod, test)
# Code fitted values appropriately
fitted[fitted < 0] <- 0
fitted[fitted > 1] <- 1
# Return residuals
return(test$overreporting - fitted)
}
# Define desired model formula
mod1_formula <- "overreporting ~ black + hisp + asian + other + mixed + male + educ + income + birthyr +  birthyrsq + polknow + rep + ind + ideo7ltc + attmeeting"
# Using lapply, feed the function row indices of fold and correct model formula.
# Unlist and square the residuals it returns, then take the mean.
# Store in a named vector object.
mse_1 <- mean(unlist(lapply(1:10, pred_fold, mod1_formula))^2)
mse_1
# Create model object
or_relig_ols <- lm(overreporting ~ black + hisp + asian + other + mixed + male + educ + income + birthyr +  birthyrsq + polknow + rep + ind + ideo7ltc + attmeeting + catholic + prot + bornagain + chatthtl, cces2010sub)
# View summary
summary(or_relig_ols)
# Define desired model formula
mod2_formula <- "overreporting ~ black + hisp + asian + other + mixed + male + educ + income + birthyr +  birthyrsq + polknow + rep + ind + ideo7ltc + attmeeting + catholic + prot + bornagain + chatthtl"
# Using lapply, feed the function row indices of fold and correct model formula.
# Unlist and square the residuals it returns, then take the mean.
# Store in a named vector object.
mse_2 <- mean(unlist(lapply(1:10, pred_fold, mod2_formula))^2)
mse_2
abs(mse_1 - mse_2)
get_lambdaCV <- function(grid, UB, covariates){
lambda_MSE <- data.frame()
for(l in grid){
resid_Kfold <- c()
for(i in 1:10){
# Define training data
train_X <- covariates[folds != i,]
train_y <- y[folds != i,]
# Define test data
test_X <- covariates[folds == i,]
test_y <- y[folds == i,]
# Manual ridge based on matrix definition of beta ridge
beta_ridge <- solve(( t(train_X)%*% train_X + l*diag(nrow = ncol(train_X), ncol = ncol(train_X)))) %*% t(train_X) %*% train_y
fitted <- beta_ridge %*% test_y
# Code fitted values given our outcome
fitted[fitted < 0] <- 0
fitted[fitted > 1] <- 1
# Store
resid_Kfold <- c(resid_Kfold, test_y - fitted)
}
# Calculate MSE for each lambda
l_res <- data.frame("lambda"=l,"MSE"=mean(resid_Kfold^2))
# Add to table
lambda_MSE <- rbind(lambda_MSE, l_res)
}
# Return the minimized MSE and its associated lambda
return(lambda_MSE[which(lambda_MSE$MSE==min(lambda_MSE$MSE)),][1,])
}
# This y is used for both ridge models
y <- data.matrix(cces2010sub[,.(overreporting)])
# Specify ridge data
# Non-religious covariates
X_nr <- apply(data.matrix(cces2010sub[,.(black, hisp, asian, other , mixed , male , educ , income , birthyr ,  birthyrsq , polknow , rep , ind , ideo7ltc , attmeeting)]),2,scale)
# We will use our model from above to estimate parameters needed for the upper bound of lambda.
Y_hat <- predict(or_ols)
e_hat <- cces2010sub$overreporting - Y_hat
N_K_1 <- nrow(X_nr) - (length(or_ols$coefficients))
numerator <- ((t(e_hat) %*% e_hat) / N_K_1)
denominator <- t(or_ols$coefficients) %*% or_ols$coefficients
# Calculate and print the upper bound
lambdaUB_NR <- 2*(numerator/denominator)
lambdaUB_NR
# Lambda grid over the theoretically "best" neighborhood
# this sequence contains 93 values to try between 0 and the upper bound
best_neighborhood_NR <- seq(0, lambdaUB_NR, 0.000001)
nr_l_best <- get_lambdaCV(best_neighborhood_NR,lambdaUB_NR, X_nr)
nr_l_best
alt_lambda_seq <- seq(0, 0.5, 0.001)
nr_l_alt <- get_lambdaCV(alt_lambda_seq, 0.5, X_nr)
nr_l_alt
# Check cv.glmnet in "best" neighborhood
cv.glmnet(X_nr, y, lambda=best_neighborhood_NR, nfolds = 10)
# Check cv.glmnet no neighborhood
cv.glmnet(X_nr, y, nfolds = 10)
# Re-define X but use same y
X_r <- apply(data.matrix(cces2010sub[,.(black, hisp, asian, other , mixed , male , educ , income , birthyr ,  birthyrsq , polknow , rep , ind , ideo7ltc , attmeeting, catholic, prot, bornagain, chatthtl)]), 2, scale)
# We will use our model from above to estimate parameters needed for the upper bound of lambda.
# Use religious OLS
Y_hat <- predict(or_relig_ols)
e_hat <- cces2010sub$overreporting - Y_hat
N_K_1 <- nrow(cces2010sub) - (length(or_relig_ols$coefficients))
numerator <- ((t(e_hat) %*% e_hat) / N_K_1)
denominator <- t(or_relig_ols$coefficients) %*% or_relig_ols$coefficients
# Calculate and print the upper bound
lambdaUB_R <- 2*(numerator/denominator)
lambdaUB_R
# Lambda grid over the theoretically "best" neighborhood
# this sequence contains 31 values to try between 0 and the upper bound
best_neighborhood_R <- seq(0,lambdaUB_R, 0.000001)
r_l_best <- get_lambdaCV(best_neighborhood_R, lambdaUB_R, X_r)
r_l_best
# Also try alternative grid
alt_lambda_seq <- seq(0, 0.2, 0.001)
r_l_alt <- get_lambdaCV(alt_lambda_seq, 0.002, X_r)
r_l_alt
# Check cv.glmnet in "best" neighborhood
cv.glmnet(X_r, y, lambda=best_neighborhood_R, nfolds = 10)
# Check cv.glmnet no neighborhood
cv.glmnet(X_r, y, nfolds = 10)
# Create model
or_nr_ridge <- glmnet(X_nr, y, alpha = 0, lambda = nr_l_best$lambda, thresh = 10^-100, standardize=FALSE)
or_nr_ridge$lambda
# MPE
nr_ridge_mpe <- mean((predict(or_nr_ridge, X_nr)-y)^2)
nr_ridge_mpe
mse_1 - nr_ridge_mpe
# Use an alternative from cv.glmnet
or_r_ridge <- glmnet(X_r, y, alpha = 0, lambda = r_l_best$lambda, thres = 10^-100, standardize=TRUE, maxit = 10^7)
or_r_ridge$lambda
# MPE
r_ridge_mpe <- mean((predict(or_r_ridge, X_r)-y)^2)
r_ridge_mpe
r_ridge_mpe - mse_2
# Define training data
train_X <- covariates[folds != i,]
fitted <- beta_ridge %*% test_y
# Define training data
train_X <- covariates[folds != i,]
get_lambdaCV <- function(grid, UB, covariates){
lambda_MSE <- data.frame()
for(l in grid){
resid_Kfold <- c()
for(i in 1:10){
# Define training data
train_X <- covariates[folds != i,]
train_y <- y[folds != i,]
# Define test data
test_X <- covariates[folds == i,]
test_y <- y[folds == i,]
# Manual ridge based on matrix definition of beta ridge
beta_ridge <- solve(( t(train_X)%*% train_X + l*diag(nrow = ncol(train_X), ncol = ncol(train_X)))) %*% t(train_X) %*% train_y
fitted <- beta_ridge %*% test_y
# Code fitted values given our outcome
fitted[fitted < 0] <- 0
fitted[fitted > 1] <- 1
# Store
resid_Kfold <- c(resid_Kfold, test_y - fitted)
}
# Calculate MSE for each lambda
l_res <- data.frame("lambda"=l,"MSE"=mean(resid_Kfold^2))
# Add to table
lambda_MSE <- rbind(lambda_MSE, l_res)
}
# Return the minimized MSE and its associated lambda
return(lambda_MSE[which(lambda_MSE$MSE==min(lambda_MSE$MSE)),][1,])
}
current.code <- as.package("Midterm")
load_all(current.code)
rm(list = c("mle"))` to remove the conflicts
ds
d
d
quit()
stop()
